# web_scrapy

Important-
1.	To ensure accuracy, obtain up-to-date information.
2.	Have the capacity for massive scale.

Use case - By pricing your products perfectly, you can make sure that your competitors aren’t undercutting you, which makes you more likely to nab customers

Key- is to be able to take advantage of rapid price drops so you can buy during lightning sales

Workflow- 
1.	Imbedded the product name as required the application in the url in compare/compare/spider/crawler.py
2.	Run the compare application using the Anaconda Prompt
3.	Go to compare root folder and hit the command – scrapy crawl infiniabot
4.	The output of the script will get save by the name items.csv in the compare root folder.


